{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify companies based on their websites\n",
    "\n",
    "The scope of this notebook is to analyze the capabilities of OpenAI's GPT3.5 to classify enterprises based on their company's website. To achieve this, this notebook will try and solve the following problems: \n",
    "\n",
    "- How to find an enterprise website with as much info as a proprietary Email-address (e.g. exclude addresses like @gmail.com, @outlook.com)\n",
    "- Extract relevant keywords from the enterprise's website\n",
    "- Classify the entry based on the extracted keywords\n",
    "- Allow the analyst to export the result into a .csv file based on their requirements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/tobiq/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/tobiq/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import requests;\n",
    "import os;\n",
    "import nltk;\n",
    "import pandas as pd;\n",
    "import json;\n",
    "import openai\n",
    "from dotenv import load_dotenv;\n",
    "from bs4 import BeautifulSoup;\n",
    "from pymongo.mongo_client import MongoClient\n",
    "from pymongo.server_api import ServerApi\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "load_dotenv();\n",
    "\n",
    "# Set constant variables\n",
    "mongo_url = os.getenv(\"MONGO_URL\");\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\");\n",
    "client = MongoClient(mongo_url, server_api=ServerApi('1'))\n",
    "\n",
    "# Set configuration variables\n",
    "# These are used to determine whether to run a task that might already have taken place,\n",
    "# e.g. crawl a website, update keywords or predicting a category with OpenAI\n",
    "update_category = False\n",
    "\n",
    "# Download stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Establish MongoDB Connection\n",
    "db = client['python_openapi']\n",
    "collection = db['enterprises']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test connection (optional)\n",
    "\n",
    "Create the necessary DB structure with a dummy entry to test the connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#   enterprise_dummy_entry = {\n",
    "#     \"name\": \"Test Enterprises GmbH\",\n",
    "#     \"domain\": \"test.com\",\n",
    "#     \"email\": \"dummy@test.com\",\n",
    "#     \"category\": \"\",\n",
    "#     \"keywords\": [\"one\", \"two\", \"three\"]\n",
    "#   }\n",
    "#   collection.insert_one(enterprise_dummy_entry)\n",
    "#   print(\"Created dummy entry\")\n",
    "# except Exception as e:\n",
    "#   print(e)\n",
    "\n",
    "# Delete all dummy entries again\n",
    "# try:\n",
    "#   db = client['python_openapi']\n",
    "#   collection = db['enterprises']\n",
    "#   collection.delete_many({\"domain\": \"test.com\"})\n",
    "# except Exception as e:\n",
    "#   print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload CSV Data\n",
    "\n",
    "The minimum data structure provided should be\n",
    "\n",
    "| Name | Email |\n",
    "| ---- | ----- |\n",
    "| Test Enterprises GmbH | dummy@test.com |\n",
    "\n",
    "Use the following template to start: \n",
    "\n",
    "```csv\n",
    "name;email\n",
    "Test Enterprises GmbH;dummy@test.com\n",
    "```\n",
    "\n",
    "Data will be stored in MongoDB. Duplicated domains will be overwritten by the newest email address and name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting entry for domain apple.com\n",
      "Done importing 1 entries from csv file ./enterprises.csv\n"
     ]
    }
   ],
   "source": [
    "csv_input_path = './enterprises.csv'\n",
    "csv_input_data = pd.read_csv(csv_input_path, sep=\";\")\n",
    "json_enterprise_data = []\n",
    "\n",
    "try:\n",
    "  for _, row in csv_input_data.iterrows():\n",
    "    entry = {\n",
    "      \"name\": row[\"name\"],\n",
    "      \"domain\": row[\"email\"].split('@')[1],\n",
    "      \"email\": row[\"email\"],\n",
    "      \"corpus\": \"\",\n",
    "      \"industry\": \"\",\n",
    "      \"keywords\": [],\n",
    "      \"confidence_keywords\": 0,\n",
    "      \"confidence_industry\": 0\n",
    "    }\n",
    "    json_enterprise_data.append(entry)\n",
    "\n",
    "  json_data = json.loads(json.dumps(json_enterprise_data, indent=4))\n",
    "\n",
    "  for entry in json_data:\n",
    "    if collection.find_one({\"domain\": entry[\"domain\"]}) is None:\n",
    "      print('Inserting entry for domain', entry[\"domain\"])\n",
    "      collection.insert_one(entry)\n",
    "    else:\n",
    "      print('Updating entry for domain', entry[\"domain\"])\n",
    "      collection.update_one({\"domain\": entry[\"domain\"]}, {\"$set\": entry})\n",
    "  print(\"Done importing \" + str(len(json_data)) + \" entries from csv file \" + csv_input_path)\n",
    "except Exception as e:\n",
    "  print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crawl the website from the given domain\n",
    "\n",
    "Assuming all domains stored in MongoDB are valid (you could add a validation step right above), the following code will extract all defined tags from the corporate website and enrich the MongoDB entry accordingly. It will\n",
    "\n",
    "1. Read all enterprise entries\n",
    "2. Check if entry is to be updated (to avoid multiple, accidential crawls of the same domain)\n",
    "3. Crawl the website by it's domain using the https - protocol\n",
    "4. Append the response corpus to the MongoDB entry\n",
    "\n",
    "> Note: This process runs synchronously and may take a while. To avoid recrawling already existing entries, set the variable 'update_corpus' to False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling domain apple.com\n",
      "Adding corpus with 500 characters for domain apple.com\n"
     ]
    }
   ],
   "source": [
    "enterprises = collection.find({})\n",
    "html_tags_to_crawl = ['h1', 'h2', 'h3', 'p'] # Add and remove tags you want to find keywords in\n",
    "http_protocol = 'https'                      # Set to 'http' or 'https'\n",
    "languages = ['english', 'german']            # Add whatever languages should be filtered for stopwords\n",
    "update_corpus = True                         # Whether or not to re-crawl a website\n",
    "max_corpus_size = 500                        # Increase maximum corpus size to be sent to OpenAI\n",
    "\n",
    "# Remove stopworlds in all defined languages\n",
    "def remove_stopwords(text):\n",
    "  filtered_text = text\n",
    "  for language in languages:\n",
    "    filtered_text = [word for word in filtered_text if(word.lower() not in stopwords.words(language))]\n",
    "  return filtered_text;\n",
    "\n",
    "# Crawl a website and return a text corpus\n",
    "def create_corpus_from_domain(domain):\n",
    "  url = http_protocol + '://' + domain;\n",
    "  response = requests.get(url)\n",
    "  if(response.status_code != 200):\n",
    "    print(\"Error while trying to crawl domain \" + domain + \", status code: \" + response.status_code)\n",
    "    return \"\"\n",
    "  else:\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    corpus = \"\"\n",
    "    for tag in soup.find_all(html_tags_to_crawl):\n",
    "      text = word_tokenize(tag.text)\n",
    "      filtered_text_list = remove_stopwords(text)\n",
    "      filtered_text = \" \".join(filtered_text_list)[0:100]\n",
    "      corpus += filtered_text\n",
    "    return corpus[0:max_corpus_size]\n",
    "\n",
    "# Update database entries with the crawled text corpus\n",
    "def enrich_enterprise_with_corpus(enterprise):\n",
    "  # Update existing corpus data\n",
    "  if(enterprise['corpus'] != \"\" and update_corpus == True):\n",
    "    print(\"Updating corpus with \" + str(max_corpus_size) + \" characters for domain \" + enterprise[\"domain\"])\n",
    "    enterprise_corpus = create_corpus_from_domain(domain=enterprise[\"domain\"])\n",
    "    enterprise[\"corpus\"] = enterprise_corpus\n",
    "    collection.update_one({\"domain\": enterprise[\"domain\"]}, {\"$set\": enterprise})\n",
    "\n",
    "  # If the corpus is not empty and updates are disabled, skip this entry\n",
    "  elif(enterprise['corpus'] != \"\" and update_corpus == False):\n",
    "    print(\"Skipping corpus update for domain \" + enterprise[\"domain\"])\n",
    "\n",
    "  # Default: Crawl a new entry\n",
    "  else:\n",
    "    print(\"Crawling domain \" + enterprise[\"domain\"])\n",
    "    enterprise_corpus = create_corpus_from_domain(domain=enterprise[\"domain\"])\n",
    "    enterprise[\"corpus\"] = enterprise_corpus\n",
    "    print(\"Adding corpus with \" + str(max_corpus_size) + \" characters for domain \" + enterprise[\"domain\"])\n",
    "    collection.update_one({\"domain\": enterprise[\"domain\"]}, {\"$set\": enterprise})\n",
    "\n",
    "for enterprise in enterprises:\n",
    "  enrich_enterprise_with_corpus(enterprise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate keywords and update entry\n",
    "\n",
    "After entries are created and their websites crawled, we'll use OpenAI's GPT3.5 to generate keywords for each entry and update the MongoDB entry accordingly. The following code will: \n",
    "\n",
    "1. Read all enterprise entries\n",
    "2. Generate keywords for each entry\n",
    "3. Generate keyword confidence\n",
    "4. Update the MongoDB entry accordingly\n",
    "\n",
    "### Prompt\n",
    "\n",
    "You are a marketing expert at an international agency. Extract keywords from a text corpus describing a product or service and return a JSON Object adhering to the following rules:\n",
    "\n",
    "- Omit comments or explanations and return the JSON object.\n",
    "- Format the JSON Object as: `{ keywords: <keywords>, confidence: <confidence> }`\n",
    "- Use a JSON Array for `<keywords>` and include only the top ten keywords that best describe the product in the text corpus.\n",
    "- For `<confidence>`, assign a score from 1 (lowest) to 10 (highest) indicating how well the keywords match the product or service in the text corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keywords for domain apple.com are ['Apple', 'iPhone 15 Pro', 'Titanium', 'strong', 'light', 'New camera', 'New design', 'Newphoria', 'Killers Flower Moontheaters', 'Available early next year U.S']\n"
     ]
    }
   ],
   "source": [
    "enterprises = collection.find({})\n",
    "update_keywords = False;\n",
    "system_prompt_keywords = \"You are a marketing expert at an international agency. Extract keywords from a text corpus describing a product or service and return a JSON Object adhering to the following rules:\\n\\n- Omit comments or explanations and return the JSON object.\\n- Format the JSON Object as: `{ keywords: <keywords>, confidence: <confidence> }`\\n- Use a JSON Array for `<keywords>` and include only the top ten keywords that best describe the product in the text corpus.\\n- For `<confidence>`, assign a score from 1 (lowest) to 10 (highest) indicating how well the keywords match the product or service in the text corpus.\"\n",
    "\n",
    "def fetch_keywords_for_enterprise(enterprise):\n",
    "  response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "      { \"role\": \"system\", \"content\": system_prompt_keywords },\n",
    "      { \"role\": \"user\", \"content\": enterprise['corpus'] }\n",
    "    ],\n",
    "    temperature=0,\n",
    "    max_tokens=256,\n",
    "    top_p=1,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0\n",
    "  )\n",
    "  response_json = json.loads(response['choices'][0]['message']['content'])\n",
    "  return response_json\n",
    "\n",
    "def enrich_enterprise_with_keywords(enterprise):\n",
    "  # Throw exception if corpus is missing\n",
    "  if(enterprise['corpus'] == \"\"):\n",
    "    raise Exception(\"Corpus is missing for domain \" + enterprise[\"domain\"] + '. Make sure to run the Crawler first!')\n",
    "  # Skip entry if keywords are already present and update is turned off\n",
    "  elif(enterprise['keywords'].__len__() > 0 and update_keywords == False):\n",
    "    print(\"Skipping keywords update for domain \" + enterprise[\"domain\"])\n",
    "  else:\n",
    "    keyword_response = fetch_keywords_for_enterprise(enterprise)\n",
    "    enterprise['keywords'] = keyword_response['keywords']\n",
    "    print(\"Keywords for domain \" + enterprise[\"domain\"] + \" are \" + str(enterprise['keywords']))\n",
    "    enterprise['confidence_keywords'] = keyword_response['confidence']\n",
    "    collection.update_one({\"domain\": enterprise[\"domain\"]}, {\"$set\": enterprise})\n",
    "\n",
    "\n",
    "for enterprise in enterprises:\n",
    "    enrich_enterprise_with_keywords(enterprise)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate industry and update entry\n",
    "\n",
    "Finally, the domain will be categorized into one of the available industries. The following code will:\n",
    "\n",
    "- Read all enterprise entries\n",
    "- Generate industry categories for each entry\n",
    "- Update the MongoDB entry accordingly\n",
    "\n",
    "### Prompt\n",
    "\n",
    "As a marketing expert at an international agency, categorize the company based on the provided JSON array of keywords into one of the following industries and return a JSON Object adhering to the following rules:\n",
    "\n",
    "- Omit comments or explanations and return the JSON object.\n",
    "- Format the JSON Object as: `{ industry: <industry>, confidence: <confidence> }`\n",
    "- Replace `<industry>` with the industry name based on your best categorization result.\n",
    "- Replace `<confidence>` with a score from 1 (lowest) to 10 (highest) indicating how well the industry matches the provided keywords.\n",
    "- Before you answer, verify that your reply is part of the industry array below\n",
    "- If it is not, choose an industry that is closest to your reply.\n",
    "\n",
    "These are the industries: \n",
    "```\n",
    "[ \"Technology\", \"Healthcare\", \"Finance\", \"Retail\", \"Manufacturing\", \"Automotive\", \"Energy\", \"Telecommunications\", \"Aerospace\", \"Hospitality\", \"Entertainment\", \"Consumer Goods\", \"Pharmaceuticals\", \"Construction\", \"Transportation\", \"Real Estate\", \"Food and Beverage\", \"Media\", \"Insurance\", \"Consulting\", \"Other Services\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Industry for domain apple.com is Technology with a confidence of 9\n"
     ]
    }
   ],
   "source": [
    "enterprises = collection.find({})\n",
    "update_industry = False;\n",
    "system_prompt_industry = \"As a marketing expert at an international agency, categorize the company based on the provided JSON array of keywords into one of the following industries and return a JSON Object adhering to the following rules:\\n\\n- Omit comments or explanations and return the JSON object.\\n- Format the JSON Object as: `{ industry: <industry>, confidence: <confidence> }`\\n- Replace `<industry>` with the industry name based on your best categorization result.\\n- Replace `<confidence>` with a score from 1 (lowest) to 10 (highest) indicating how well the industry matches the provided keywords.\\n- Before you answer, verify that your reply is part of the industry array below\\n- If it is not, choose an industry that is closest to your reply.\\n\\nThese are the industries: \\n```\\n[ \\\"Technology\\\", \\\"Healthcare\\\", \\\"Finance\\\", \\\"Retail\\\", \\\"Manufacturing\\\", \\\"Automotive\\\", \\\"Energy\\\", \\\"Telecommunications\\\", \\\"Aerospace\\\", \\\"Hospitality\\\", \\\"Entertainment\\\", \\\"Consumer Goods\\\", \\\"Pharmaceuticals\\\", \\\"Construction\\\", \\\"Transportation\\\", \\\"Real Estate\\\", \\\"Food and Beverage\\\", \\\"Media\\\", \\\"Insurance\\\", \\\"Consulting\\\", \\\"Other Services\\\"]\"\n",
    "\n",
    "def fetch_industry_for_enterprise(enterprise):\n",
    "  response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "      {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": system_prompt_industry\n",
    "      },\n",
    "      {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": str(enterprise['keywords'])\n",
    "      }\n",
    "    ],\n",
    "    temperature=1,\n",
    "    max_tokens=256,\n",
    "    top_p=1,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0\n",
    "  )\n",
    "  response_json = json.loads(response['choices'][0]['message']['content'])\n",
    "  return response_json\n",
    "\n",
    "def enrich_enterprise_with_industry(enterprise):\n",
    "  # Throw exception if keywords array has 0 length\n",
    "  if(enterprise['keywords'].__len__() == 0):\n",
    "    raise Exception(\"Keywords array is empty for domain \" + enterprise[\"domain\"] + '. Make sure to run the first prompt before trying to categorize!')\n",
    "  # Skip entry if keywords are already available and update industry is turned off\n",
    "  elif(enterprise['industry'] != \"\" and update_industry == False):\n",
    "    print(\"Skipping industry update for domain \" + enterprise[\"domain\"])\n",
    "  else:\n",
    "    industry_response = fetch_industry_for_enterprise(enterprise)\n",
    "    enterprise['industry'] = industry_response['industry']\n",
    "    enterprise['confidence_industry'] = industry_response['confidence']\n",
    "    print(\"Industry for domain \" + enterprise[\"domain\"] + \" is \" + enterprise['industry'] + \" with a confidence of \" + str(enterprise['confidence_industry']))\n",
    "    collection.update_one({\"domain\": enterprise[\"domain\"]}, {\"$set\": enterprise})\n",
    "\n",
    "for enterprise in enterprises:\n",
    "  enrich_enterprise_with_industry(enterprise)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
